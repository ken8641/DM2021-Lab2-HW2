{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f962b376",
   "metadata": {},
   "source": [
    "## Importing packages needed and read files from data-ID and emotion.csv\n",
    "## Notice: \n",
    "1.Using pd.read_json to read 'tweets_DM.json', remember using the right orientation\n",
    "\n",
    "2.json_normalize for extracting the nest structures(_source) to 2 levels\n",
    "\n",
    "3.finally we sort using the 'tweet.tweet_id' and save them to 'df1', and pass it to the data's new column 'text'\n",
    "## Using pd.query to distinguish Test and Train dataset and sort them with tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab111e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ken\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import numpy as np\n",
    "#import plotly\n",
    "#from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plotly.offline.init_notebook_mode()\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import cufflinks as cf\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "\n",
    "data=pd.read_csv('data_identification.csv')\n",
    "emotion1=pd.read_csv('emotion.csv')\n",
    "\n",
    "emotion1=emotion1.sort_values(by=['tweet_id'])\n",
    "emotion1.head()\n",
    "\n",
    "\n",
    "\n",
    "data=data.sort_values(by=['tweet_id'])\n",
    "\n",
    "\n",
    "emotion1=emotion1.sort_values(by=['tweet_id'])\n",
    "emotion1\n",
    "\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "df=pd.read_json(\"tweets_DM.json\",lines='true',orient='columns')\n",
    "df1=pd.json_normalize(df['_source'],max_level=2)\n",
    "\n",
    "\n",
    "\n",
    "df1=df1.sort_values(by=['tweet.tweet_id'])\n",
    "df1\n",
    "\n",
    "df1\n",
    "data['text']=df1['tweet.text']\n",
    "data['text']\n",
    "train=data.query('identification==\"train\"')\n",
    "train=train.sort_values(by='tweet_id')\n",
    "test=data.query('identification==\"test\"')\n",
    "train\n",
    "test=test.sort_values(by='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc3206",
   "metadata": {},
   "source": [
    "## Using sort at first according to the twitter_id, then add a new column index for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1742fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index']=emotion1['emotion'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266f5e0",
   "metadata": {},
   "source": [
    "## Make a function for tweets text cleaning\n",
    "re.sub can replace the redundant symbols of tweets to null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038dd30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_tweets(tweet):\n",
    "    \n",
    "    # remove URL\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    \n",
    "    # Remove usernames\n",
    "    tweet = re.sub(r\"@[^\\s]+[\\s]?\",'',tweet)\n",
    "    \n",
    "    # remove special characters \n",
    "    tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "    \n",
    "    # remove Numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b8c68",
   "metadata": {},
   "source": [
    "## Using apply to clean train['text'] and test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83945bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(clean_tweets)\n",
    "test['text'] = test['text'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3240f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c9545",
   "metadata": {},
   "source": [
    "## I personally found some LH symbols that seem to be redudant and clean them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f2ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].apply(lambda x: x.replace(\"LH\",\"\"))\n",
    "test['text']=test['text'].apply(lambda x: x.replace(\"LH\",\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c12c6",
   "metadata": {},
   "source": [
    "## importing training requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5cc0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from  tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572cfb23",
   "metadata": {},
   "source": [
    "## combi(Train+Test) used for w2v training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3ce1343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1867535, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi = train.append(test, ignore_index=True, sort=True)\n",
    "combi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3646520c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             516017\n",
       "anticipation    248935\n",
       "trust           205478\n",
       "sadness         193437\n",
       "disgust         139101\n",
       "fear             63999\n",
       "surprise         48729\n",
       "anger            39867\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['index'].value_counts()\n",
    "#using these frequencies afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511957a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf17b0",
   "metadata": {},
   "source": [
    "## combi cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72783246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>thanks for waking me up God</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>thanks for waking me up God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>With expectation there you will find anticipat...</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>With expectation there you will find anticipat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>glad has discovered Rochdale Borough last week...</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>glad has discovered Rochdale Borough last week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>Only down  We need The D to step up and just h...</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>Only down  We need The D to step up and just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "      <td>I want to an Insecure recap video with a guy o...</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>I want to an Insecure recap video with a guy o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>OMGNo no no What What No you cant leave it lik...</td>\n",
       "      <td>0x1c7f19</td>\n",
       "      <td>OMGNo no no What What No you cant leave it lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>look at this guy  youre not a cowboy  Boomer</td>\n",
       "      <td>0x1c7f1a</td>\n",
       "      <td>look at this guy  youre not a cowboy  Boomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Airlines in America SAY one thing in disingenu...</td>\n",
       "      <td>0x1c7f1b</td>\n",
       "      <td>Airlines in America SAY one thing in disingenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>roosterpisces janetshoemake MargaretSteib Mar...</td>\n",
       "      <td>0x1c7f1c</td>\n",
       "      <td>roosterpisces janetshoemake MargaretSteib Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>We hope your Halloween was a happy one and wit...</td>\n",
       "      <td>0x1c7f1d</td>\n",
       "      <td>We hope your Halloween was a happy one and wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identification         index  \\\n",
       "0          train           joy   \n",
       "1          train  anticipation   \n",
       "2          train           joy   \n",
       "3          train           joy   \n",
       "4          train       disgust   \n",
       "5          train  anticipation   \n",
       "6          train           joy   \n",
       "7          train  anticipation   \n",
       "8          train         trust   \n",
       "9          train           joy   \n",
       "\n",
       "                                                text  tweet_id  \\\n",
       "0                        thanks for waking me up God  0x1c7f10   \n",
       "1  With expectation there you will find anticipat...  0x1c7f11   \n",
       "2  glad has discovered Rochdale Borough last week...  0x1c7f14   \n",
       "3  Only down  We need The D to step up and just h...  0x1c7f15   \n",
       "4  I want to an Insecure recap video with a guy o...  0x1c7f16   \n",
       "5  OMGNo no no What What No you cant leave it lik...  0x1c7f19   \n",
       "6       look at this guy  youre not a cowboy  Boomer  0x1c7f1a   \n",
       "7  Airlines in America SAY one thing in disingenu...  0x1c7f1b   \n",
       "8   roosterpisces janetshoemake MargaretSteib Mar...  0x1c7f1c   \n",
       "9  We hope your Halloween was a happy one and wit...  0x1c7f1d   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0                        thanks for waking me up God  \n",
       "1  With expectation there you will find anticipat...  \n",
       "2  glad has discovered Rochdale Borough last week...  \n",
       "3  Only down  We need The D to step up and just h...  \n",
       "4  I want to an Insecure recap video with a guy o...  \n",
       "5  OMGNo no no What What No you cant leave it lik...  \n",
       "6       look at this guy  youre not a cowboy  Boomer  \n",
       "7  Airlines in America SAY one thing in disingenu...  \n",
       "8   roosterpisces janetshoemake MargaretSteib Mar...  \n",
       "9  We hope your Halloween was a happy one and wit...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi['tidy_tweet'] = np.vectorize(remove_pattern)(combi['text'], \"@[\\w]*\") \n",
    "combi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfcd4eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>thanks for waking me up God</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>thanks for waking me up God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>With expectation there you will find anticipat...</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>With expectation there you will find anticipat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>glad has discovered Rochdale Borough last week...</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>glad has discovered Rochdale Borough last week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>Only down  We need The D to step up and just h...</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>Only down  We need The D to step up and just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "      <td>I want to an Insecure recap video with a guy o...</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>I want to an Insecure recap video with a guy o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>OMGNo no no What What No you cant leave it lik...</td>\n",
       "      <td>0x1c7f19</td>\n",
       "      <td>OMGNo no no What What No you cant leave it lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>look at this guy  youre not a cowboy  Boomer</td>\n",
       "      <td>0x1c7f1a</td>\n",
       "      <td>look at this guy  youre not a cowboy  Boomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Airlines in America SAY one thing in disingenu...</td>\n",
       "      <td>0x1c7f1b</td>\n",
       "      <td>Airlines in America SAY one thing in disingenu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>roosterpisces janetshoemake MargaretSteib Mar...</td>\n",
       "      <td>0x1c7f1c</td>\n",
       "      <td>roosterpisces janetshoemake MargaretSteib Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>We hope your Halloween was a happy one and wit...</td>\n",
       "      <td>0x1c7f1d</td>\n",
       "      <td>We hope your Halloween was a happy one and wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identification         index  \\\n",
       "0          train           joy   \n",
       "1          train  anticipation   \n",
       "2          train           joy   \n",
       "3          train           joy   \n",
       "4          train       disgust   \n",
       "5          train  anticipation   \n",
       "6          train           joy   \n",
       "7          train  anticipation   \n",
       "8          train         trust   \n",
       "9          train           joy   \n",
       "\n",
       "                                                text  tweet_id  \\\n",
       "0                        thanks for waking me up God  0x1c7f10   \n",
       "1  With expectation there you will find anticipat...  0x1c7f11   \n",
       "2  glad has discovered Rochdale Borough last week...  0x1c7f14   \n",
       "3  Only down  We need The D to step up and just h...  0x1c7f15   \n",
       "4  I want to an Insecure recap video with a guy o...  0x1c7f16   \n",
       "5  OMGNo no no What What No you cant leave it lik...  0x1c7f19   \n",
       "6       look at this guy  youre not a cowboy  Boomer  0x1c7f1a   \n",
       "7  Airlines in America SAY one thing in disingenu...  0x1c7f1b   \n",
       "8   roosterpisces janetshoemake MargaretSteib Mar...  0x1c7f1c   \n",
       "9  We hope your Halloween was a happy one and wit...  0x1c7f1d   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0                        thanks for waking me up God  \n",
       "1  With expectation there you will find anticipat...  \n",
       "2  glad has discovered Rochdale Borough last week...  \n",
       "3  Only down  We need The D to step up and just h...  \n",
       "4  I want to an Insecure recap video with a guy o...  \n",
       "5  OMGNo no no What What No you cant leave it lik...  \n",
       "6       look at this guy  youre not a cowboy  Boomer  \n",
       "7  Airlines in America SAY one thing in disingenu...  \n",
       "8   roosterpisces janetshoemake MargaretSteib Mar...  \n",
       "9  We hope your Halloween was a happy one and wit...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi.tidy_tweet = combi.tidy_tweet.str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "combi.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea6f99",
   "metadata": {},
   "source": [
    "## if length of the words>3, x.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba66d387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>thanks for waking me up God</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>thanks waking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>With expectation there you will find anticipat...</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>With expectation there will find anticipation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>glad has discovered Rochdale Borough last week...</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>glad discovered Rochdale Borough last week tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>Only down  We need The D to step up and just h...</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>Only down need step just hang there keep Faith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "      <td>I want to an Insecure recap video with a guy o...</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>want Insecure recap video with YouTube channel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>OMGNo no no What What No you cant leave it lik...</td>\n",
       "      <td>0x1c7f19</td>\n",
       "      <td>OMGNo What What cant leave like this LethalWeapon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>look at this guy  youre not a cowboy  Boomer</td>\n",
       "      <td>0x1c7f1a</td>\n",
       "      <td>look this youre cowboy Boomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Airlines in America SAY one thing in disingenu...</td>\n",
       "      <td>0x1c7f1b</td>\n",
       "      <td>Airlines America thing disingenuous campaigns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>roosterpisces janetshoemake MargaretSteib Mar...</td>\n",
       "      <td>0x1c7f1c</td>\n",
       "      <td>roosterpisces janetshoemake MargaretSteib Mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>We hope your Halloween was a happy one and wit...</td>\n",
       "      <td>0x1c7f1d</td>\n",
       "      <td>hope your Halloween happy with just right amount</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identification         index  \\\n",
       "0          train           joy   \n",
       "1          train  anticipation   \n",
       "2          train           joy   \n",
       "3          train           joy   \n",
       "4          train       disgust   \n",
       "5          train  anticipation   \n",
       "6          train           joy   \n",
       "7          train  anticipation   \n",
       "8          train         trust   \n",
       "9          train           joy   \n",
       "\n",
       "                                                text  tweet_id  \\\n",
       "0                        thanks for waking me up God  0x1c7f10   \n",
       "1  With expectation there you will find anticipat...  0x1c7f11   \n",
       "2  glad has discovered Rochdale Borough last week...  0x1c7f14   \n",
       "3  Only down  We need The D to step up and just h...  0x1c7f15   \n",
       "4  I want to an Insecure recap video with a guy o...  0x1c7f16   \n",
       "5  OMGNo no no What What No you cant leave it lik...  0x1c7f19   \n",
       "6       look at this guy  youre not a cowboy  Boomer  0x1c7f1a   \n",
       "7  Airlines in America SAY one thing in disingenu...  0x1c7f1b   \n",
       "8   roosterpisces janetshoemake MargaretSteib Mar...  0x1c7f1c   \n",
       "9  We hope your Halloween was a happy one and wit...  0x1c7f1d   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0                                      thanks waking  \n",
       "1  With expectation there will find anticipation ...  \n",
       "2  glad discovered Rochdale Borough last week tod...  \n",
       "3  Only down need step just hang there keep Faith...  \n",
       "4  want Insecure recap video with YouTube channel...  \n",
       "5  OMGNo What What cant leave like this LethalWeapon  \n",
       "6                      look this youre cowboy Boomer  \n",
       "7  Airlines America thing disingenuous campaigns ...  \n",
       "8  roosterpisces janetshoemake MargaretSteib Mari...  \n",
       "9   hope your Halloween happy with just right amount  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi.tidy_tweet = combi.tidy_tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "combi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "975a0ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     [thanks, waking]\n",
       "1    [With, expectation, there, will, find, anticip...\n",
       "2    [glad, discovered, Rochdale, Borough, last, we...\n",
       "3    [Only, down, need, step, just, hang, there, ke...\n",
       "4    [want, Insecure, recap, video, with, YouTube, ...\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = combi.tidy_tweet.apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab421bf3",
   "metadata": {},
   "source": [
    "## Using stemming technique referred in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2055f1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        [thank, wake]\n",
       "1    [with, expect, there, will, find, anticip, rev...\n",
       "2    [glad, discov, rochdal, borough, last, week, t...\n",
       "3    [onli, down, need, step, just, hang, there, ke...\n",
       "4    [want, insecur, recap, video, with, youtub, ch...\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import * \n",
    "stemmer = PorterStemmer() \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a8d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>thanks for waking me up God</td>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>thank wake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>With expectation there you will find anticipat...</td>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>with expect there will find anticip revel thur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>glad has discovered Rochdale Borough last week...</td>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>glad discov rochdal borough last week today cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>Only down  We need The D to step up and just h...</td>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>onli down need step just hang there keep faith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "      <td>I want to an Insecure recap video with a guy o...</td>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>want insecur recap video with youtub channel b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>OMGNo no no What What No you cant leave it lik...</td>\n",
       "      <td>0x1c7f19</td>\n",
       "      <td>omgno what what cant leav like thi lethalweapon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>look at this guy  youre not a cowboy  Boomer</td>\n",
       "      <td>0x1c7f1a</td>\n",
       "      <td>look thi your cowboy boomer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Airlines in America SAY one thing in disingenu...</td>\n",
       "      <td>0x1c7f1b</td>\n",
       "      <td>airlin america thing disingenu campaign piss s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>trust</td>\n",
       "      <td>roosterpisces janetshoemake MargaretSteib Mar...</td>\n",
       "      <td>0x1c7f1c</td>\n",
       "      <td>roosterpisc janetshoemak margaretsteib marizel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>We hope your Halloween was a happy one and wit...</td>\n",
       "      <td>0x1c7f1d</td>\n",
       "      <td>hope your halloween happi with just right amount</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identification         index  \\\n",
       "0          train           joy   \n",
       "1          train  anticipation   \n",
       "2          train           joy   \n",
       "3          train           joy   \n",
       "4          train       disgust   \n",
       "5          train  anticipation   \n",
       "6          train           joy   \n",
       "7          train  anticipation   \n",
       "8          train         trust   \n",
       "9          train           joy   \n",
       "\n",
       "                                                text  tweet_id  \\\n",
       "0                        thanks for waking me up God  0x1c7f10   \n",
       "1  With expectation there you will find anticipat...  0x1c7f11   \n",
       "2  glad has discovered Rochdale Borough last week...  0x1c7f14   \n",
       "3  Only down  We need The D to step up and just h...  0x1c7f15   \n",
       "4  I want to an Insecure recap video with a guy o...  0x1c7f16   \n",
       "5  OMGNo no no What What No you cant leave it lik...  0x1c7f19   \n",
       "6       look at this guy  youre not a cowboy  Boomer  0x1c7f1a   \n",
       "7  Airlines in America SAY one thing in disingenu...  0x1c7f1b   \n",
       "8   roosterpisces janetshoemake MargaretSteib Mar...  0x1c7f1c   \n",
       "9  We hope your Halloween was a happy one and wit...  0x1c7f1d   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0                                         thank wake  \n",
       "1  with expect there will find anticip revel thur...  \n",
       "2  glad discov rochdal borough last week today cu...  \n",
       "3  onli down need step just hang there keep faith...  \n",
       "4  want insecur recap video with youtub channel b...  \n",
       "5    omgno what what cant leav like thi lethalweapon  \n",
       "6                        look thi your cowboy boomer  \n",
       "7  airlin america thing disingenu campaign piss s...  \n",
       "8  roosterpisc janetshoemak margaretsteib marizel...  \n",
       "9   hope your halloween happi with just right amount  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])    \n",
    "combi['tidy_tweet'] = tokenized_tweet\n",
    "combi.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc1050",
   "metadata": {},
   "source": [
    "## Use bow_vectorizer to fit_transform combi['tidy_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "665165a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffb4c40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1867535, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi.reset_index(drop=True)\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "bow = bow_vectorizer.fit_transform(combi['tidy_tweet'])\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2edd1",
   "metadata": {},
   "source": [
    "## Model_w2v training process:\n",
    "    \n",
    "    1.prepare tokenized text\n",
    "    2.settings fits(vector_size,window_size,ignore_count,skip-gram,hs,negative sampling,no.cores,seed)\n",
    "    3.train the model with tokenized text, using epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a3c099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(253704890, 287562000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_tweet = combi['tidy_tweet'].apply(lambda x: x.split()) # tokenizing \n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            vector_size=200, # desired no. of features/independent variables\n",
    "            window=5, # context window size\n",
    "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling\n",
    "            workers= 32, # no.of cores\n",
    "            seed = 34\n",
    ") \n",
    "\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(combi['tidy_tweet']), epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191128c",
   "metadata": {},
   "source": [
    "## function of tokens to word_vector process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0274ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v.wv[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72db2799",
   "metadata": {},
   "source": [
    "## After putting values using loop, we construct a dataframe to save it in and check its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "135ed9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1867535, 200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecdd84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas(desc=\"progress-bar\") \n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8b549",
   "metadata": {},
   "source": [
    "## Import taggeddocoument to add_label function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64ab4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(twt):\n",
    "    output = []\n",
    "    for i, s in zip(twt.index, twt):\n",
    "        output.append(TaggedDocument(s, [\"tweet_\" + str(i)]))\n",
    "    return output\n",
    "\n",
    "labeled_tweets = add_label(tokenized_tweet) # label all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c2696ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af886cd0",
   "metadata": {},
   "source": [
    "## Transform emotion string to number to train in xgb-classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c82de159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  emotion_num(emotion):\n",
    "        if  emotion=='joy':\n",
    "            return 0\n",
    "        \n",
    "        if  emotion=='anticipation':  \n",
    "            return 1\n",
    "        if   emotion=='trust':     \n",
    "            return 2\n",
    "        if emotion=='sadness':\n",
    "            return 3\n",
    "        if emotion=='disgust':\n",
    "            return 4\n",
    "        if emotion=='fear':\n",
    "            return 5\n",
    "        if emotion=='surprise':\n",
    "            return 6\n",
    "        if emotion=='anger':\n",
    "            return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a7bc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index']=train['index'].apply(emotion_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0428ad90",
   "metadata": {},
   "source": [
    "## Reset_index due to the sort of tweet_id and divide bow into train_bow and test_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "640c8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.reset_index(drop=True)\n",
    "from xgboost import XGBClassifier\n",
    "train_bow = bow[:1455563,:] \n",
    "test_bow = bow[1455563:,:] \n",
    "\n",
    "# splitting data into training and validation set \n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(bow[:100000], train['index'][:100000], random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c0b91",
   "metadata": {},
   "source": [
    "## if we don't reset train_index above, we'll get errors when we put ytrain.index and yvalid.index in, due to the no. would possibly exceed the limit of the train_w2v matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2ae8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = wordvec_df.iloc[:1455563,:]\n",
    "test_w2v = wordvec_df.iloc[1455563:,:]\n",
    "\n",
    "xtrain_w2v = train_w2v.iloc[ytrain.index,:]\n",
    "xvalid_w2v = train_w2v.iloc[yvalid.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b3e3a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3323333333333333"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(max_depth=6, n_estimators=1000).fit(xtrain_bow, ytrain)\n",
    "prediction = xgb_model.predict(xvalid_bow)\n",
    "f1_score(yvalid, prediction ,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df4fda",
   "metadata": {},
   "source": [
    "## Trying Trying and Falling back\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75771464",
   "metadata": {},
   "source": [
    "I transfer the number back into emotions and upload it to the competition. And i also try roberta training, but the grade \n",
    "was lower than this version.(Roberta cost me nearly about 2 weeks, so it's really disappointing that it's not working better) \n",
    "\n",
    "i work it using emotion predictor(unsupervised pretrained model learning)\n",
    "and i use colab to run, debugging cost me about 90 percents of time. At last i finally run it but the test data is too large,\n",
    "and i split about 410000 texts run inpendently with 42 folds each with 10000 texts.\n",
    "Combining and Waiting, writing it to submission.csv but not good work...but it's a good experience\n",
    "https://colab.research.google.com/drive/1QDtn3t2ZLAV5Gz4yfHYAsRkJpkORdivw?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e7291",
   "metadata": {},
   "source": [
    "Spent too long time running following codes(the trained wv model above), a little bit upset when waiting all day long without any improvements, hoping to give more\n",
    "advices if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=1000, nthread= 3,use_label_encoder=False).fit(xtrain_w2v, ytrain) \n",
    "prediction = xgb.predict(xvalid_w2v)\n",
    "f1_score(yvalid, prediction,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abcbc3",
   "metadata": {},
   "source": [
    "## Future Expectation and My experience in this competition\n",
    "Cause the imcompletion of the execution, i have no time to do hyper-tuning and model-esembling.\n",
    "Really happy to do such codeworks in this course. Though i always fall behind the class progress, and fail the orientation test.\n",
    "I believe i've done my best in nfl analysis and the final exam.  Data-analysist is my dream job and this is the first time.\n",
    "Thanks teachers and tas for solving problems with students actively and without leaving any rest encouraging us to have new \n",
    "thoughts about data-mining. If there is any chance for me to attend the alike works again, i'll have some basic data-mining\n",
    "coding ability. Thanks a lot again, and hoping that i can still ask questions about this region. Really nice course and i will\n",
    "recommend to my classmates to join as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain_w2v, label=ytrain) \n",
    "dvalid = xgb.DMatrix(xvalid_w2v, label=yvalid) \n",
    "dtest = xgb.DMatrix(test_w2v)\n",
    "# Parameters that we are going to tune \n",
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda69de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
